"""
MLE-Bench Adapter for Swarm-Evo

æœ¬æ¨¡å—æ˜¯ Swarm-Evo é¡¹ç›®ä¸ MLE-Bench è¯„æµ‹æ¡†æ¶çš„é€‚é…å±‚ã€‚
åœ¨ MLE-Bench å®¹å™¨ç¯å¢ƒä¸­ä½œä¸ºå…¥å£ç‚¹è¿è¡Œï¼Œè´Ÿè´£ï¼š
1. ç¯å¢ƒå˜é‡é€‚é…ä¸é…ç½®åˆå§‹åŒ–
2. å·¥ä½œç©ºé—´è®¾ç½®
3. Agent ç³»ç»Ÿåˆå§‹åŒ–
4. ç«èµ›æ‰§è¡Œä¸ç»“æœè¾“å‡º
"""

import os
import asyncio
import shutil
import json
from pathlib import Path
from typing import Optional


async def run_adapter():
    """
    MLE-Bench é€‚é…å™¨ä¸»å…¥å£å‡½æ•°ã€‚
    
    æ‰§è¡Œæµç¨‹:
        1. ç¯å¢ƒå˜é‡é¢„è®¾ï¼ˆå¿…é¡»åœ¨ import config ä¹‹å‰ï¼‰
        2. åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
        3. åŠ è½½é…ç½®
        4. åˆ›å»º Agent ç³»ç»Ÿç»„ä»¶
        5. è¿è¡Œç«èµ›
        6. è¾“å‡ºç»“æœæ–‡ä»¶
    """
    
    # =========================================
    # ç¬¬ä¸€é˜¶æ®µï¼šç¯å¢ƒå˜é‡é¢„è®¾
    # å¿…é¡»åœ¨å¯¼å…¥ utils.config ä¹‹å‰å®Œæˆ
    # =========================================
    
    competition_id = os.environ.get("COMPETITION_ID", "unknown_competition")
    
    # MLE-Bench å®¹å™¨ç¯å¢ƒå˜é‡é»˜è®¤å€¼
    # è¿™äº›å€¼ä¼šè¢«å®¹å™¨ä¼ å…¥çš„ç¯å¢ƒå˜é‡è¦†ç›–
    env_defaults = {
        # LLM API é…ç½® - éœ€è¦ä»å®¹å™¨ç¯å¢ƒè·å–æˆ–ç¡¬ç¼–ç 
        "API_KEY": os.environ.get("API_KEY", "your_api_key_here"),
        "API_BASE": os.environ.get("API_BASE", "https://dashscope.aliyuncs.com/compatible-mode/v1"),
        "MODEL_NAME": os.environ.get("MODEL_NAME", "qwen-max"),
        
        # æ—¥å¿—é…ç½®
        "LOG_LEVEL": "INFO",
        "LOG_DIR": "/home/logs",
        
        # å®éªŒé…ç½®
        "RANDOM_SEED": "42",
        "MAX_CONCURRENT_AGENTS": "1",
        "AGENT_TIMEOUT": "3600",
        "AGENT_NUM": os.environ.get("AGENT_NUM", "1"),
        "AGENT_CONFIG_DIR": "/home/agent/core/config/agent.json",
        
        # MLE-Bench é…ç½®
        "MLE_BENCH_COMPETITION": competition_id,
        "MLE_BENCH_SERVER_URL": "http://localhost:5000",
        "MLE_BENCH_WORKSPACE_DIR": "/home",
        "MLE_BENCH_TIME_LIMIT": os.environ.get("TIME_LIMIT", "12"),
        "MLE_BENCH_EPOCH_LIMIT": os.environ.get("STEP_LIMIT", "100"),
        "MLE_BENCH_PRIVATE_DATA_DIR": "/private/data",
        
        # Conda ç¯å¢ƒ
        "CONDA_ENV_NAME": os.environ.get("CONDA_ENV_NAME", "base"),
        
        # ä»»åŠ¡æ‰§è¡Œé…ç½®
        "INIT_TASK_NUM": "2",
        "EXPLORE_RATIO": "0.6",
        "EPOCH_TASK_NUM": "1",
    }
    
    for key, value in env_defaults.items():
        if key not in os.environ or os.environ.get(key, "").strip() == "":
            os.environ[key] = value
    
    # =========================================
    # ç¬¬äºŒé˜¶æ®µï¼šå¯¼å…¥é¡¹ç›®æ¨¡å—ï¼ˆåœ¨ç¯å¢ƒå˜é‡è®¾ç½®ä¹‹åï¼‰
    # =========================================
    
    from utils.config import get_config
    from utils.logger_system import init_logger, log_msg
    from core.agent.agent_pool import AgentPool
    from core.execution.pipeline import Pipeline
    from core.execution.journal import Journal
    from core.execution.iteration_controller import IterationController
    
    # =========================================
    # ç¬¬ä¸‰é˜¶æ®µï¼šåˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    # =========================================
    
    logs_dir = Path("/home/logs")
    logs_dir.mkdir(parents=True, exist_ok=True)
    init_logger(str(logs_dir))
    log_msg("INFO", "=" * 50)
    log_msg("INFO", "Swarm-Evo MLE-Bench Adapter å¯åŠ¨")
    log_msg("INFO", f"Competition: {competition_id}")
    log_msg("INFO", "=" * 50)
    
    # =========================================
    # ç¬¬å››é˜¶æ®µï¼šMLE-Bench å·¥ä½œç©ºé—´è®¾ç½®
    # =========================================
    
    # MLE-Bench æ ‡å‡†ç›®å½•ç»“æ„
    workspace_dir = Path("/home")
    data_dir = workspace_dir / "data"
    submission_dir = workspace_dir / "submission"
    code_dir = workspace_dir / "code"
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    submission_dir.mkdir(parents=True, exist_ok=True)
    code_dir.mkdir(parents=True, exist_ok=True)
    
    log_msg("INFO", f"å·¥ä½œç›®å½•: {workspace_dir}")
    log_msg("INFO", f"æ•°æ®ç›®å½•: {data_dir}")
    log_msg("INFO", f"æäº¤ç›®å½•: {submission_dir}")
    
    # =========================================
    # ç¬¬äº”é˜¶æ®µï¼šåŠ è½½é…ç½®
    # =========================================
    
    try:
        config = get_config()
        log_msg("INFO", "é…ç½®åŠ è½½æˆåŠŸ")
    except Exception as e:
        log_msg("ERROR", f"é…ç½®åŠ è½½å¤±è´¥: {e}")
        return
    
    # =========================================
    # ç¬¬å…­é˜¶æ®µï¼šè¯»å–ç«èµ›æè¿°
    # =========================================
    
    description_content = ""
    description_candidates = [
        workspace_dir / "description.md",  # MLE-Bench é»˜è®¤ä½ç½®: /home/description.md
        data_dir / "description.md",
    ]
    
    for desc_path in description_candidates:
        if desc_path.exists():
            try:
                description_content = desc_path.read_text(encoding="utf-8")
                log_msg("INFO", f"ç«èµ›æè¿°å·²åŠ è½½: {desc_path}")
                break
            except Exception as e:
                log_msg("WARNING", f"æ— æ³•è¯»å– {desc_path}: {e}")
    
    if not description_content:
        log_msg("WARNING", "æœªæ‰¾åˆ°ç«èµ›æè¿°æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤æè¿°")
        description_content = f"""
# Kaggle Competition: {competition_id}

## Data Location
Competition data is available at: {data_dir}

## Submission
Save your predictions to: {submission_dir / "submission.csv"}
"""
    
    # =========================================
    # ç¬¬ä¸ƒé˜¶æ®µï¼šåˆ›å»º LLM å®¢æˆ·ç«¯å’Œ Agent Pool
    # =========================================
    
    try:
        llm = config.create_langchain_llm()
        log_msg("INFO", "LangChain LLM å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        log_msg("ERROR", f"LLM å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {e}")
        return
    
    # åŠ è½½ Agent é…ç½®
    agent_config_path = Path("/home/agent/core/config/agent.json")
    if not agent_config_path.exists():
        # å›é€€åˆ°é¡¹ç›®å†…è·¯å¾„
        agent_config_path = Path("core/config/agent.json")
    
    if agent_config_path.exists():
        try:
            with open(agent_config_path, "r", encoding="utf-8") as f:
                agent_config_dict = json.load(f)
            agent_config_dict["conda_env_name"] = config.conda_env_name
            log_msg("INFO", f"Agent é…ç½®åŠ è½½æˆåŠŸ: {agent_config_path}")
        except Exception as e:
            log_msg("ERROR", f"Agent é…ç½®åŠ è½½å¤±è´¥: {e}")
            return
    else:
        log_msg("WARNING", f"Agent é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {agent_config_path}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        agent_config_dict = {
            "model_type": config.model_name,
            "max_steps": 50,
            "tool_config": [],
            "conda_env_name": config.conda_env_name,
        }
    
    try:
        agent_pool = AgentPool.from_configs(
            agents_num=config.agent_num,
            config=agent_config_dict,
            llm=llm
        )
        log_msg("INFO", f"AgentPool åˆ›å»ºæˆåŠŸï¼Œå…± {config.agent_num} ä¸ª Agent")
    except Exception as e:
        log_msg("ERROR", f"AgentPool åˆ›å»ºå¤±è´¥: {e}")
        return
    
    # =========================================
    # ç¬¬å…«é˜¶æ®µï¼šåˆ›å»º Journal å’Œ Pipeline
    # =========================================
    
    try:
        journal = Journal()
        log_msg("INFO", "Journal åˆå§‹åŒ–å®Œæˆ")
        
        pipeline = Pipeline(journal)
        pipeline.initialize()
        log_msg("INFO", "Pipeline åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        log_msg("ERROR", f"Journal/Pipeline åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # =========================================
    # ç¬¬ä¹é˜¶æ®µï¼šåˆ›å»ºå¹¶è¿è¡Œ IterationController
    # =========================================
    
    try:
        controller = IterationController(
            agent_pool=agent_pool,
            task_pipeline=pipeline,
            journal=journal,
            config=config,
            competition_description=description_content
        )
        log_msg("INFO", "IterationController åˆ›å»ºæˆåŠŸ")
        
        log_msg("INFO", "å¼€å§‹ç«èµ›æ‰§è¡Œ...")
        await controller.run_competition()
        log_msg("INFO", "ç«èµ›æ‰§è¡Œå®Œæˆ")
        
    except Exception as e:
        log_msg("ERROR", f"ç«èµ›æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
    
    # =========================================
    # ç¬¬åé˜¶æ®µï¼šè¾“å‡ºç»“æœæ–‡ä»¶ï¼ˆMLE-Bench åˆè§„ï¼‰
    # =========================================
    
    log_msg("INFO", "æ•´ç†è¾“å‡ºæ–‡ä»¶...")
    
    submission_file = submission_dir / "submission.csv"
    
    # 1. æ£€æŸ¥æäº¤æ–‡ä»¶
    # [NEW Logic] ä¼˜å…ˆå°è¯•ä»æœ€ä½³æ–¹æ¡ˆæ¢å¤
    try:
        best_node = journal.get_best_node()
        if best_node and best_node.archive_path and os.path.exists(best_node.archive_path):
            log_msg("INFO", f"æ­£åœ¨ä»å½’æ¡£æ¢å¤æœ€ä½³æ–¹æ¡ˆ: {best_node.archive_path}")
            import zipfile
            with zipfile.ZipFile(best_node.archive_path, 'r') as zip_ref:
                zip_ref.extractall(workspace_dir)
            log_msg("INFO", "âœ… æœ€ä½³æ–¹æ¡ˆæ–‡ä»¶å·²æ¢å¤åˆ°å·¥ä½œç›®å½•")
    except Exception as e:
        log_msg("WARNING", f"å°è¯•æ¢å¤æœ€ä½³æ–¹æ¡ˆå¤±è´¥: {e}")

    if submission_file.exists():
        log_msg("INFO", f"âœ… æäº¤æ–‡ä»¶å­˜åœ¨: {submission_file}")
    else:
        log_msg("WARNING", "âŒ æäº¤æ–‡ä»¶æœªç”Ÿæˆ! å°è¯•å…œåº•æŸ¥æ‰¾...")
        # å°è¯•ä»å·¥ä½œç›®å½•æŸ¥æ‰¾
        for candidate in workspace_dir.glob("**/submission.csv"):
            try:
                shutil.copy2(candidate, submission_file)
                log_msg("INFO", f"ä» {candidate} å¤åˆ¶æäº¤æ–‡ä»¶")
                break
            except Exception as e:
                log_msg("WARNING", f"å¤åˆ¶å¤±è´¥: {e}")
    
    # 2. å¤åˆ¶ä»£ç åˆ° /home/code
    solution_candidates = [
        workspace_dir / "solution.py",
        workspace_dir / "code" / "solution.py",
    ]
    for src in solution_candidates:
        if src.exists():
            try:
                shutil.copy2(src, code_dir / "solution.py")
                log_msg("INFO", f"å·²å¤åˆ¶ solution.py åˆ° {code_dir}")
                break
            except Exception as e:
                log_msg("WARNING", f"å¤åˆ¶ solution.py å¤±è´¥: {e}")
    
    # 3. å¤åˆ¶å¿«ç…§ç›®å½•
    snapshots_src = workspace_dir / ".snapshots"
    if snapshots_src.exists():
        try:
            shutil.copytree(snapshots_src, code_dir / ".snapshots", dirs_exist_ok=True)
            log_msg("INFO", f"å·²å¤åˆ¶ .snapshots åˆ° {code_dir}")
        except Exception as e:
            log_msg("WARNING", f"å¤åˆ¶ .snapshots å¤±è´¥: {e}")
    
    # 4. å¤åˆ¶ Journal åˆ°æ—¥å¿—ç›®å½•
    journal_src = workspace_dir / "journal.json"
    if journal_src.exists():
        try:
            shutil.copy2(journal_src, logs_dir / "journal.json")
            log_msg("INFO", f"å·²å¤åˆ¶ journal.json åˆ° {logs_dir}")
        except Exception as e:
            log_msg("WARNING", f"å¤åˆ¶ journal.json å¤±è´¥: {e}")
    
    # 5. å±•ç¤ºæœ€ä½³ç»“æœ
    try:
        best_node = journal.get_best_node()
        if best_node:
            log_msg("INFO", f"æœ€ä½³æ–¹æ¡ˆ ID: {best_node.id}, Score: {best_node.score}")
        else:
            log_msg("WARNING", "æœªæ‰¾åˆ°æœ‰æ•ˆæ–¹æ¡ˆ")
    except Exception as e:
        log_msg("WARNING", f"è·å–æœ€ä½³æ–¹æ¡ˆå¤±è´¥: {e}")
    
    log_msg("INFO", "=" * 50)
    log_msg("INFO", "Swarm-Evo MLE-Bench Adapter ç»“æŸ")
    log_msg("INFO", "=" * 50)


if __name__ == "__main__":
    print("\nğŸš€ å¯åŠ¨ Swarm-Evo MLE-Bench é€‚é…å™¨\n")
    asyncio.run(run_adapter())
